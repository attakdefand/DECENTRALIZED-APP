groups:
- name: comprehensive-alerts
  rules:
  # SLO-based alerts
  - alert: APIAvailabilitySLOBreached
    expr: 100 - (sum(increase(http_requests_total{status=~"5.."}[1h])) / sum(increase(http_requests_total[1h]))) * 100 < 99.9
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "API availability SLO breached"
      description: "API availability is below 99.9% (current value: {{ $value }}%)"

  - alert: APILatencySLOBreached
    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 0.25
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "API latency SLO breached"
      description: "API p95 latency is above 250ms (current value: {{ $value }}s)"

  # Service health alerts
  - alert: APIServiceDown
    expr: up{job="api-service"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "API service is down"
      description: "API service is not responding to Prometheus scrapes"

  - alert: IndexerServiceDown
    expr: up{job="indexer-service"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Indexer service is down"
      description: "Indexer service is not responding to Prometheus scrapes"

  - alert: KeepersServiceDown
    expr: up{job="keepers-service"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Keepers service is down"
      description: "Keepers service is not responding to Prometheus scrapes"

  - alert: IPFSServiceDown
    expr: up{job="ipfs-service"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "IPFS service is down"
      description: "IPFS service is not responding to Prometheus scrapes"

  # Performance alerts
  - alert: HighRequestRate
    expr: sum(rate(http_requests_total[5m])) > 1000
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "High request rate"
      description: "Request rate is above 1000 requests/second (current value: {{ $value }})"

  - alert: HighErrorRate
    expr: (sum(rate(http_request_errors_total[5m])) / sum(rate(http_requests_total[5m]))) * 100 > 1
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "High error rate"
      description: "Error rate is above 1% (current value: {{ $value }}%)"

  - alert: HighLatencyP99
    expr: histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 0.5
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "High latency (p99)"
      description: "p99 latency is above 500ms (current value: {{ $value }}s)"

  # Resource usage alerts
  - alert: HighMemoryUsage
    expr: rate(process_resident_memory_bytes[5m]) > 1073741824  # 1GB
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage"
      description: "Memory usage is above 1GB (current value: {{ $value }} bytes)"

  - alert: HighCPUUsage
    expr: rate(process_cpu_seconds_total[5m]) > 1  # 1 CPU core
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage"
      description: "CPU usage is above 1 core (current value: {{ $value }} cores)"

  # Business metrics alerts
  - alert: LowOrderVolume
    expr: increase(orders_processed_total[1h]) < 10
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Low order volume"
      description: "Order volume is below 10 orders/hour (current value: {{ $value }})"

  - alert: HighOrderCancellationRate
    expr: (increase(orders_cancelled_total[1h]) / increase(orders_processed_total[1h])) * 100 > 5
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "High order cancellation rate"
      description: "Order cancellation rate is above 5% (current value: {{ $value }}%)"

  # Synthetic test alerts
  - alert: SyntheticTestFailed
    expr: synthetic_test_success == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Synthetic test failed"
      description: "A synthetic test has failed (value: {{ $value }})"

  # Tracing alerts
  - alert: HighTraceErrorRate
    expr: (sum(rate(traces_spans{status="error"}[5m])) / sum(rate(traces_spans[5m]))) * 100 > 1
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "High trace error rate"
      description: "Trace error rate is above 1% (current value: {{ $value }}%)"